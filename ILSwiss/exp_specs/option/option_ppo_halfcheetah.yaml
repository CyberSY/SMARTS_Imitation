meta_data:
  script_path: run_scripts/option_ppo_exp_script.py
  exp_name: option_ppo_halfcheetah
  description: Train an agent using option-ppo
  using_gpus: true
  num_workers: 1
  num_gpu_per_worker: 1
  num_cpu_per_worker: 8
  mem_per_worker: 16gb
  partitions: p100,max12hours
  node_exclusions: gpu048,gpu024,gpu025,gpu012,gpu027
# -----------------------------------------------------------------------------
variables:
  seed: [723894]

# -----------------------------------------------------------------------------
constants:
  net_size: 256
  num_hidden_layers: 2
  option_dim: 4

  rl_alg_params:
    num_epochs: 301
    num_steps_per_epoch: 10000
    num_steps_between_train_calls: 2048
    num_train_steps_per_train_call: 1
    num_steps_per_eval: 10000
    max_path_length: 1000
    min_steps_before_training: 2048

    eval_deterministic: true

    batch_size: 64
    replay_buffer_size: 50000
    no_terminal: false
    wrap_absorbing: false

    save_best: false
    freq_saving: 10
    save_replay_buffer: false
    save_environment: false
    save_algorithm: false

  option_ppo_params:
    clip_eps: 0.2
    reward_scale: 1.0
    discount: 0.99
    policy_lr: 0.0003
    option_lr: 0.0003
    vf_lr: 0.0003
    value_l2_reg: 0.001
    gae_tau: 0.9
    update_epoch: 10
    mini_batch_size: 128
    lambda_entropy_policy: 0.0
    lambda_entropy_option: 0.01

  env_specs:
    env_creator: "mujoco"
    env_name: "halfcheetah"
    env_kwargs: {}
    env_num: 8
    eval_env_seed: 78236
    training_env_seed: 24495
