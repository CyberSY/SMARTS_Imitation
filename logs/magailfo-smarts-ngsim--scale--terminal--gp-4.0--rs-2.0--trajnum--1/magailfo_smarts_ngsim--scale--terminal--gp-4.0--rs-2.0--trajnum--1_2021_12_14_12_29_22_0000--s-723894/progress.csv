policy_0 Disc CE Loss,policy_0 Disc Acc,policy_0 Grad Pen,policy_0 Grad Pen W,policy_0 Disc Rew Mean,policy_0 Disc Rew Std,policy_0 Disc Rew Max,policy_0 Disc Rew Min,policy_0 Reward Scale,policy_0 QF1 Loss,policy_0 QF2 Loss,policy_0 Alpha Loss,policy_0 Policy Loss,policy_0 Q1 Predictions Mean,policy_0 Q1 Predictions Std,policy_0 Q1 Predictions Max,policy_0 Q1 Predictions Min,policy_0 Q2 Predictions Mean,policy_0 Q2 Predictions Std,policy_0 Q2 Predictions Max,policy_0 Q2 Predictions Min,policy_0 Alpha Mean,policy_0 Alpha Std,policy_0 Alpha Max,policy_0 Alpha Min,policy_0 Log Pis Mean,policy_0 Log Pis Std,policy_0 Log Pis Max,policy_0 Log Pis Min,policy_0 Policy mu Mean,policy_0 Policy mu Std,policy_0 Policy mu Max,policy_0 Policy mu Min,policy_0 Policy log std Mean,policy_0 Policy log std Std,policy_0 Policy log std Max,policy_0 Policy log std Min,Test agent_0 Success Rate,Test agent_0 Collision Rate,Test agent_0 Distance Mean,Test agent_0 Distance Std,Test agent_0 Distance Max,Test agent_0 Distance Min,Test agent_0 Rewards Mean,Test agent_0 Rewards Std,Test agent_0 Rewards Max,Test agent_0 Rewards Min,Test agent_0 Returns Mean,Test agent_0 Returns Std,Test agent_0 Returns Max,Test agent_0 Returns Min,Test agent_0 Actions Mean,Test agent_0 Actions Std,Test agent_0 Actions Max,Test agent_0 Actions Min,Test agent_1 Success Rate,Test agent_1 Collision Rate,Test agent_1 Distance Mean,Test agent_1 Distance Std,Test agent_1 Distance Max,Test agent_1 Distance Min,Test agent_1 Rewards Mean,Test agent_1 Rewards Std,Test agent_1 Rewards Max,Test agent_1 Rewards Min,Test agent_1 Returns Mean,Test agent_1 Returns Std,Test agent_1 Returns Max,Test agent_1 Returns Min,Test agent_1 Actions Mean,Test agent_1 Actions Std,Test agent_1 Actions Max,Test agent_1 Actions Min,Test agent_2 Success Rate,Test agent_2 Collision Rate,Test agent_2 Distance Mean,Test agent_2 Distance Std,Test agent_2 Distance Max,Test agent_2 Distance Min,Test agent_2 Rewards Mean,Test agent_2 Rewards Std,Test agent_2 Rewards Max,Test agent_2 Rewards Min,Test agent_2 Returns Mean,Test agent_2 Returns Std,Test agent_2 Returns Max,Test agent_2 Returns Min,Test agent_2 Actions Mean,Test agent_2 Actions Std,Test agent_2 Actions Max,Test agent_2 Actions Min,Test agent_3 Success Rate,Test agent_3 Collision Rate,Test agent_3 Distance Mean,Test agent_3 Distance Std,Test agent_3 Distance Max,Test agent_3 Distance Min,Test agent_3 Rewards Mean,Test agent_3 Rewards Std,Test agent_3 Rewards Max,Test agent_3 Rewards Min,Test agent_3 Returns Mean,Test agent_3 Returns Std,Test agent_3 Returns Max,Test agent_3 Returns Min,Test agent_3 Actions Mean,Test agent_3 Actions Std,Test agent_3 Actions Max,Test agent_3 Actions Min,Test agent_4 Success Rate,Test agent_4 Collision Rate,Test agent_4 Distance Mean,Test agent_4 Distance Std,Test agent_4 Distance Max,Test agent_4 Distance Min,Test agent_4 Rewards Mean,Test agent_4 Rewards Std,Test agent_4 Rewards Max,Test agent_4 Rewards Min,Test agent_4 Returns Mean,Test agent_4 Returns Std,Test agent_4 Returns Max,Test agent_4 Returns Min,Test agent_4 Actions Mean,Test agent_4 Actions Std,Test agent_4 Actions Max,Test agent_4 Actions Min,Test Ep. Len. Mean,Test Ep. Len. Std,Test Ep. Len. Max,Test Ep. Len. Min,Num Paths,Exploration agent_0 Success Rate,Exploration agent_0 Collision Rate,Exploration agent_0 Distance Mean,Exploration agent_0 Distance Std,Exploration agent_0 Distance Max,Exploration agent_0 Distance Min,Exploration agent_0 Rewards Mean,Exploration agent_0 Rewards Std,Exploration agent_0 Rewards Max,Exploration agent_0 Rewards Min,Exploration agent_0 Returns Mean,Exploration agent_0 Returns Std,Exploration agent_0 Returns Max,Exploration agent_0 Returns Min,Exploration agent_0 Actions Mean,Exploration agent_0 Actions Std,Exploration agent_0 Actions Max,Exploration agent_0 Actions Min,Exploration agent_1 Success Rate,Exploration agent_1 Collision Rate,Exploration agent_1 Distance Mean,Exploration agent_1 Distance Std,Exploration agent_1 Distance Max,Exploration agent_1 Distance Min,Exploration agent_1 Rewards Mean,Exploration agent_1 Rewards Std,Exploration agent_1 Rewards Max,Exploration agent_1 Rewards Min,Exploration agent_1 Returns Mean,Exploration agent_1 Returns Std,Exploration agent_1 Returns Max,Exploration agent_1 Returns Min,Exploration agent_1 Actions Mean,Exploration agent_1 Actions Std,Exploration agent_1 Actions Max,Exploration agent_1 Actions Min,Exploration agent_2 Success Rate,Exploration agent_2 Collision Rate,Exploration agent_2 Distance Mean,Exploration agent_2 Distance Std,Exploration agent_2 Distance Max,Exploration agent_2 Distance Min,Exploration agent_2 Rewards Mean,Exploration agent_2 Rewards Std,Exploration agent_2 Rewards Max,Exploration agent_2 Rewards Min,Exploration agent_2 Returns Mean,Exploration agent_2 Returns Std,Exploration agent_2 Returns Max,Exploration agent_2 Returns Min,Exploration agent_2 Actions Mean,Exploration agent_2 Actions Std,Exploration agent_2 Actions Max,Exploration agent_2 Actions Min,Exploration agent_3 Success Rate,Exploration agent_3 Collision Rate,Exploration agent_3 Distance Mean,Exploration agent_3 Distance Std,Exploration agent_3 Distance Max,Exploration agent_3 Distance Min,Exploration agent_3 Rewards Mean,Exploration agent_3 Rewards Std,Exploration agent_3 Rewards Max,Exploration agent_3 Rewards Min,Exploration agent_3 Returns Mean,Exploration agent_3 Returns Std,Exploration agent_3 Returns Max,Exploration agent_3 Returns Min,Exploration agent_3 Actions Mean,Exploration agent_3 Actions Std,Exploration agent_3 Actions Max,Exploration agent_3 Actions Min,Exploration agent_4 Success Rate,Exploration agent_4 Collision Rate,Exploration agent_4 Distance Mean,Exploration agent_4 Distance Std,Exploration agent_4 Distance Max,Exploration agent_4 Distance Min,Exploration agent_4 Rewards Mean,Exploration agent_4 Rewards Std,Exploration agent_4 Rewards Max,Exploration agent_4 Rewards Min,Exploration agent_4 Returns Mean,Exploration agent_4 Returns Std,Exploration agent_4 Returns Max,Exploration agent_4 Returns Min,Exploration agent_4 Actions Mean,Exploration agent_4 Actions Std,Exploration agent_4 Actions Max,Exploration agent_4 Actions Min,Exploration Ep. Len. Mean,Exploration Ep. Len. Std,Exploration Ep. Len. Max,Exploration Ep. Len. Min,AgentMeanAverageReturn,Number of train calls total,Number of env steps total,Number of rollouts total,Train Time (s),(Previous) Eval Time (s),Sample Time (s),Epoch Time (s),Total Train Time (s),Epoch
0.7060785,0.41210938,0.710053,4.0,0.35606778,0.3517749,2.9912577,0.0064797057,2.0,1.0859878,1.0845096,-3.8812473,-0.09809213,0.0041009346,0.0011807885,0.0074709645,0.0011717316,0.0049510794,0.0026262838,0.011515848,-0.00086769986,0.1999400089993488,0.0,0.1999400089993488,0.1999400089993488,-0.4115544,0.29445466,0.3718362,-0.91052777,-0.0014285321,0.0014568475,0.0011313743,-0.0040929997,-0.0002999999,4.6017197e-11,-0.00029999984,-0.00029999993,0.07142857142857142,0.9285714285714286,1.194407105088121,1.0192785303882097,3.6117373513264486,0.10838309562046677,0.823499859470793,0.2797440377366149,5.647098445464991,0.0,103.78451086073336,87.87395113778253,308.2983359177151,10.558413635557283,-0.016509313,0.37227467,0.9911366,-0.9845383,0.07142857142857142,0.9285714285714286,1.1130078218053228,1.0337898189411652,3.6092046803353703,0.052527903325943814,0.8756917554255131,0.30464249236114205,5.681836455376798,0.0,96.8389982678414,88.52305051575527,308.72828482704296,5.163869370655526,-0.012165616,0.37042063,0.9836026,-0.9874057,0.07142857142857142,0.9285714285714286,1.2768210967033091,0.9609205394563809,3.6064498821839175,0.009197518060193755,0.8724384685847547,0.30588824627259764,5.631407402128591,0.0,111.1611243043918,83.1075607497653,316.5808191215075,1.6016145936956858,-0.01868513,0.37416357,0.9908552,-0.9830403,0.02857142857142857,0.9714285714285714,1.1824315888801047,0.8757410572071169,3.610883273743632,0.12259262268053339,0.8668964598825197,0.2968423810314769,5.610496079755052,0.0,103.03683637460803,75.44650506109606,308.45456293045754,11.332524710765345,-0.020695217,0.37107962,0.9851801,-0.98720235,0.05714285714285714,0.9428571428571428,1.3290802263669745,0.941783013448714,3.6175668635362204,0.09635549923769648,0.8225379649658443,0.26390705416251475,5.628875477903179,0.0,115.60183570477109,81.2838797936879,313.7295287940357,9.207201685142094,-0.018754955,0.35026813,0.98554945,-0.98769325,126.02857142857142,104.05931981719046,361.0,8.0,588.0,0.00510204081632653,0.8741496598639455,0.6625382713525839,0.5883981830721587,3.605543131171065,0.0032041352304628123,0.6657659824202217,0.5216383295092624,5.863771528541115,-5.631932386467023,57.5264834503813,52.440348999042214,308.3404928711131,-10.777947246455147,-0.078526735,0.61833423,0.99984795,-0.9999099,0.0017006802721088435,0.8894557823129252,0.6073558523389662,0.5688535843693064,3.61994394532133,0.0033558286276758054,0.6810759003636923,0.5240007193320939,5.783266571141226,-5.5847332914174075,52.6814525516011,49.757848453780106,308.68905727625827,-4.55876663495875,-0.08361567,0.6210402,0.99975485,-0.99983543,0.015306122448979591,0.9217687074829932,0.6802982575797646,0.7255886814290566,3.6206628050979766,0.0,0.6999302903064597,0.4719649162616433,5.806574615656729,-0.9968806939069257,59.56192506133388,64.10245103164823,324.53537578323244,-4.484633704470941,-0.067967236,0.6124273,0.9996781,-0.9999368,0.0,0.9047619047619048,0.6170221479957149,0.5444763763995456,2.759461290571991,0.0,0.7170620503592029,0.48165108135604967,5.828167113769339,-1.3036419230989509,53.46868298979464,47.79206082776145,237.0991168447645,-44.41650350958574,-0.08298103,0.6156724,0.9993937,-0.99990916,0.01020408163265306,0.9217687074829932,0.6738260592884223,0.6699065794175855,3.616271953309826,0.0,0.7362959871412682,0.47127178806232733,5.732637324518166,-5.664360665720096,58.768440932846936,58.59954781890951,308.6623789893716,-56.59398047106775,-0.074256785,0.61551833,0.9997602,-0.9998789,86.40646258503402,73.23152939144795,465.0,7.0,21.216932220493824,97,100000,588,158.84435562894214,0,743.9251710204408,902.7695266493829,1111.761305527296,0
